{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1h8VeceBxnb"
      },
      "source": [
        "# COGS 188 - Project Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTQwhvmIBxnc"
      },
      "source": [
        "# Using Reinforcement Learning & OpenAI Gym to Build a Playable Pokemon Battle AI Agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl6JWuoFBxnc"
      },
      "source": [
        "# Team Members：\n",
        "\n",
        "- Karun Mokha\n",
        "- Ke Zhang\n",
        "- Pranjli Khana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDaA_8rkBxnj"
      },
      "source": [
        "# Abstract：\n",
        "Our project aims to develop an AI agent capable of competitively playing Pokemon battles at varying levels of difficulty. We will create a battle environment within OpenAI Gym, leveraging existing open source battle simulators so we focus on developing and tuning our AI and do not get bogged down by the intricacies of the game mechanics. In the context of Pokemon battles, using AI to simulate numerous possible battle sequences can help the AI learn and determine the best move and strategy to maximize the odds of winning. Our idea is to use a technique like RL, Monte Carlo Search Tree, or Proximal Policy Optimization, where the AI evaluates potential outcomes based on each turn during battle and refines its strategy based on simulation. Essentially choosing the move that moves towards the most winning-likely scenarios based on the game state, feature engineering, and reward shaping in which we implement. Performance will be measured through the AI’s win rate in a fixed number of test battles against scripted and human opponents, the number of moves chosen by the AI which are super effective against the opponent, and adaptability-measured by the change in win rate against different scripted opponents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6qKyRJpBxnk"
      },
      "source": [
        "## Background：\n",
        "\n",
        "Since Pokémon’s video game debut with Pokémon Red, Blue, and Yellow in 1996 on the Game Boy, there have existed artificially intelligent characters that users encountered and battled against on their adventure. These in-game AI opponents followed simple, rule-based strategies to select moves and switch Pokémon, providing a baseline level of challenge for players. However, these early AI implementations were limited in their strategic depth and adaptability.\n",
        "\n",
        "The field of artificial intelligence for game playing has seen significant advancements over the years, with notable successes in complex games such as chess, Go, and Dota 2. DeepMind's AlphaGo demonstrated the power of reinforcement learning and Monte Carlo Tree Search (MCTS) in mastering the game of Go, a game with a vast state space and deep strategic complexity. AlphaGo's success was achieved by combining deep neural networks with MCTS, allowing the AI to evaluate and plan moves by simulating future states and backpropagating results through a search tree (Silver, D., et al, 2016).\n",
        "\n",
        "OpenAI developed AI agents capable of playing the multiplayer online battle arena game Dota 2 at a competitive level. These agents used a combination of reinforcement learning techniques to learn complex strategies and adapt to dynamic game environments (OpenAI, 2018).\n",
        "\n",
        "Applying these advanced AI techniques to Pokémon battles introduces unique challenges due to the game's specific mechanics, such as type advantages, move sets, and turn-based strategies. Recent research in this area has explored various approaches to developing competitive AI for Pokémon battles.\n",
        "\n",
        "For example, a project by Stanford University implemented a state-based AI algorithm for Pokémon battles using minimax and Monte Carlo methods. The Stanford project utilized Monte Carlo Tree Search (MCTS) to simulate numerous future battle sequences and select optimal moves based on the outcomes of these simulations. MCTS, combined with an evaluation function that considers the health of Pokémon, allowed the AI to make informed decisions and adapt its strategy based on the game state (Burkett, Tibrewala, Zhang, 2021).\n",
        "\n",
        "Additionally, statistical data on Generation 1 Pokémon, available from sources like Kaggle, provides a comprehensive foundation for modeling the game accurately. This data includes critical information about Pokémon stats, moves, and type interactions, which are essential for developing a realistic and competitive AI.\n",
        "\n",
        "We aim to build upon this prior work by developing an AI agent that leverages MCTS and reinforcement learning. Our goal is to create an AI that not only excels in strategic decision-making but also adapts to different opponents, providing a robust and challenging experience for players.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbJEyWZ2Bxnk"
      },
      "source": [
        "# Problem Statement：\n",
        "\n",
        "The primary problem we aim to solve is developing an AI agent capable of competitively playing Pokémon battles at varying levels of difficulty. This problem involves creating an AI that can make strategic decisions during battles to maximize its chances of winning.\n",
        "\n",
        "Our problem has multiple ML-relevant solutions, including Reinforcement Learning, Monte Carlo Search Tree, and Proximal Policy Optimization. The problem, and battles are quantifiable, as they can be expressed entirely in mathematical or logical form, through State Representation of the battle (stats, HP, condition of the pokemon), the Action Space (all possible moves the AI can take), and through its reward function. Our problem can be measured through win rate, move effectiveness, and adaptability against different opponents. It is also replicable as the problem occurs more than one, and each battle can be simulated with the same or different pokemon to ensure reliability and validity of results. It can also be trained repeatedly due to our use of OpenAI gym, making our experiments and results more reproducible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1f2Rmz2Bxnk"
      },
      "source": [
        "# Data：\n",
        "\n",
        "  **Dataset Links:**\n",
        "\n",
        "Pokemon Dataset with Team Combat on Kaggle: https://www.kaggle.com/datasets/tuannguyenvananh/pokemon-dataset-with-team-combat\n",
        "Pokemon with Stats on Kaggle: https://www.kaggle.com/datasets/abcsds/pokemon\n",
        "\n",
        "\n",
        "  This dataset has a total of 4 csv files:\n",
        "  2 files (combat.csv and pokemon.csv)\n",
        "  The other 2 files are a 6 vs 6 team match.\n",
        "\n",
        "# Dataset Descriptions:\n",
        "\n",
        "**1. Pokemon Dataset with Team Combat:**\n",
        "  - **Files:**\n",
        "    - `pokemon.csv`: 800 observations, 13 variables (Name, Type, Total Stats, HP, Attack, Defense, Speed, etc.).\n",
        "    - `combat.csv`: 50,000 observations detailing 1 vs 1 combat outcomes.\n",
        "    - `team_pokemon.csv` and `team_combat.csv`: Data for 6 vs 6 team battles, including team configurations and combat outcomes.\n",
        "  - **Observations:**\n",
        "    - `pokemon.csv`: Each observation represents a Pokémon with its name, type, and various statistics.\n",
        "    - `combat.csv`: Each observation represents the outcome of a single battle, indicating the winner.\n",
        "    - `team_pokemon.csv` and `team_combat.csv`: Represent team configurations and their combat outcomes.\n",
        "  - **Critical Variables:**\n",
        "    - **Name:** The name of the Pokémon.\n",
        "    - **Type:** The elemental type(s) of the Pokémon (e.g., Fire, Water, Grass).\n",
        "    - **Total:** The total stat value of the Pokémon.\n",
        "    - **HP:** Hit Points, the health of the Pokémon.\n",
        "    - **Attack:** The physical attack stat.\n",
        "    - **Defense:** The physical defense stat.\n",
        "    - **Speed:** The speed stat, determining move order in battles.\n",
        "    - **Combat Result:** Indicates the winner of a battle in `combat.csv`.\n",
        "  - **Special Handling and Cleaning:**\n",
        "    - **Data Cleaning:** Ensure consistency and remove duplicates. Verify battle outcomes and correct discrepancies.\n",
        "    - **Feature Engineering:** Derive features like type effectiveness, status conditions, and combined team stats.\n",
        "    - **Normalization:** Normalize numerical features for machine learning models.\n",
        "  - **Data Transformation:**\n",
        "    - **State Representation:** Convert stats and battle conditions into structured input for the AI agent. Encode type matchups and status effects.\n",
        "    - **Action Space Representation:** Define possible actions (e.g., available moves, switching Pokémon).\n",
        "    - **Reward Function Design:** Establish a reward system for effective strategies (e.g., rewarding super effective moves, penalizing ineffective ones).\n",
        "\n",
        "**2. Pokemon with Stats Dataset:**\n",
        "  - **Size:** 721 observations with variables such as ID, Name, Type 1, Type 2, Total, HP, Attack, Defense, Special Attack, Special Defense, and Speed.\n",
        "  - **Observations:** Each observation includes the Pokémon's ID, name, primary and secondary types, and base stats.\n",
        "  - **Critical Variables:**\n",
        "    - **ID:** Unique identifier for each Pokémon.\n",
        "    - **Name:** The name of the Pokémon.\n",
        "    - **Type 1:** The primary elemental type of the Pokémon.\n",
        "    - **Type 2:** The secondary elemental type, if any.\n",
        "    - **Total:** The sum of all base stats.\n",
        "    - **HP:** Hit Points, defining how much damage a Pokémon can withstand.\n",
        "    - **Attack:** Base modifier for physical attacks.\n",
        "    - **Defense:** Base damage resistance against physical attacks.\n",
        "    - **Special Attack:** Base modifier for special attacks.\n",
        "    - **Special Defense:** Base damage resistance against special attacks.\n",
        "    - **Speed:** Determines which Pokémon attacks first in a round.\n",
        "  - **Special Handling and Cleaning:**\n",
        "    - **Data Cleaning:** Ensure data consistency, especially in names and types.\n",
        "    - **Feature Engineering:** Create features such as type effectiveness.\n",
        "    - **Normalization:** Normalize base stat values for consistent comparison.\n",
        "\n",
        "  By leveraging these datasets, we can effectively train our AI agent to simulate and learn from Pokémon battles, enabling it to make strategic decisions and improve its performance over time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK_LcakSBxnk"
      },
      "source": [
        "# Proposed Solution:\n",
        "\n",
        "Our solution involves developing an AI agent using a combination of Monte Carlo Tree Search (MCTS) and Reinforcement Learning (RL) to effectively play Pokémon battles by making strategic decisions to maximize its chances of winning.\n",
        "\n",
        "### Algorithmic Description\n",
        "\n",
        "- **State Representation:**\n",
        "  - Each game state will include:\n",
        "    - Current Pokémon's stats (HP, Attack, Defense, Speed, etc.)\n",
        "    - Status conditions (e.g., Burned, Paralyzed)\n",
        "    - Move details (type, power, accuracy)\n",
        "    - Type matchups against the opponent's Pokémon\n",
        "\n",
        "- **Action Space:**\n",
        "  - The AI can choose from all available moves for the current Pokémon or switch to another Pokémon.\n",
        "  - These actions are represented in a discrete action space.\n",
        "\n",
        "- **Reward Function:**\n",
        "  - The reward function will be designed to encourage effective gameplay.\n",
        "  - Rewards will be given for actions that lead to favorable outcomes, such as dealing super effective damage or causing a status condition.\n",
        "  - Penalties will be applied for ineffective actions, such as using moves that are not very effective.\n",
        "\n",
        "- **Monte Carlo Tree Search (MCTS):**\n",
        "  - MCTS will be used to explore the potential future states of the game by simulating multiple possible sequences of actions.\n",
        "  - At each turn, the AI will use MCTS to predict the outcomes of different move sequences, choosing the move that leads to the most favorable predicted outcome.\n",
        "  - MCTS will help the AI consider the long-term effects of its actions, providing deeper strategic insight.\n",
        "\n",
        "- **Reinforcement Learning with Proximal Policy Optimization (PPO):**\n",
        "  - We will implement the PPO algorithm using the Stable Baselines3 library in Python.\n",
        "  - The PPO algorithm works by optimizing a clipped surrogate objective function, which helps to balance exploration and exploitation, and ensures stable policy updates.\n",
        "\n",
        "### Why This Solution Might Work\n",
        "\n",
        "Given our inexperience in this area, it may take some experimentation. However, we believe that by mathematically representing the battle as two equations racing each other to zero HP, we can leverage our state representation of the game to make informed decisions. Our AI will take into account complex interactions between different Pokémon moves, types, and status conditions.\n",
        "\n",
        "- **State Representation:** Allows the AI to make informed decisions based on game state.\n",
        "- **Reward Shaping:** Incentivizes the AI to learn effective battle tactics, including exploiting type advantages and predicting opponent moves.\n",
        "- **Combining MCTS with PPO:**\n",
        "  - MCTS allows exploration of long-term consequences of actions.\n",
        "  - PPO ensures efficient policy updates.\n",
        "\n",
        "### Testing & Evaluation\n",
        "\n",
        "- **Training Phase:**\n",
        "  - AI trained in a controlled environment against scripted opponents.\n",
        "  - Monitor learning progress and refine AI.\n",
        "\n",
        "- **Testing Phase:**\n",
        "  - After training, we will test AI against scripted and human opponents.\n",
        "  - Measure its win rate, move effectiveness, and adaptability against different opponents.\n",
        "\n",
        "- **Benchmark Model:**\n",
        "  - Compare the performance of our AI against rule-based opponents that follow predefined strategies.\n",
        "  - Establish a baseline for evaluating how we can fine-tune our AI.\n",
        "\n",
        "### Libraries/Function Calls We Know We Will Use\n",
        "\n",
        "- **Showdownpy:**\n",
        "  - A client for Pokémon Showdown! for Python 3.4 and 3.5.\n",
        "  - Written to make it easier to write bots, interact with users, moderate chat rooms, and collect data.\n",
        "  - [Showdownpy](https://pypi.org/project/showdownpy/)\n",
        "\n",
        "- **Stable Baselines3 Library in Python:**\n",
        "  - Implementation of PPO algorithm.\n",
        "  - [Stable Baselines3 PPO](https://stable-baselines3.readthedocs.io/en/v2.3.2/modules/ppo.html)\n",
        "\n",
        "- **OpenAI Gym**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWub56irBxnk"
      },
      "source": [
        "# Evaluation Metrics:\n",
        "\n",
        "To evaluate the performance of our AI agent using Monte Carlo Tree Search (MCTS) with the Upper Confidence Bounds (UCT) formula for decision-making, and compare it against the benchmark model, we plan to use the following metrics to quantify the AI’s effectiveness:\n",
        "\n",
        "- **Win Rate:**\n",
        "  - Percentage of battles won by the AI out of a fixed number of test battles.\n",
        "  - Win Rate = (Number of Battles Won / Total Number of Battles) x 100\n",
        "  - Derivation: During testing, the AI will participate in a series of battles. By tracking the number of battles won by the AI, we can calculate its win rate.\n",
        "\n",
        "- **Move Effectiveness:**\n",
        "  - Move Effectiveness is the percentage of moves chosen by the AI that are super effective against the opponent's Pokémon. This metric measures the AI's ability to exploit type advantages, a key strategy which will increase our AI performance.\n",
        "  - Move Effectiveness = (# of Super Effective Moves / Total # of Moves) x 100\n",
        "  - Derivation: During each battle, we track the moves selected by the AI and check their effectiveness based on type matchups.\n",
        "\n",
        "- **Adaptability:**\n",
        "  - Measured by the change in win rate when the AI faces different scripted opponents with varying strategies. This metric assesses the AI's ability to adapt to different play styles.\n",
        "  - Adaptability = ![image.png](data:image/png;base64,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), where n = number of scripted opponents.\n",
        "  - Derivation: By testing the AI against a series of scripted opponents, we can observe changes in win rate. A higher adaptability score indicates that the AI can effectively adjust its strategy based on the opponent's behavior.\n",
        "\n",
        "### Data from Battles for Training and Testing\n",
        "- **State Representation:**\n",
        "  - Each state s_t ​ includes detailed information about the game: State t ​ =(Our Array, Opponent’s Array, Current Our Pokemon, Current Opponent’s Pokemon,Turn)\n",
        "\n",
        "- **Action Space:**\n",
        "  - Set of possible actions \\(a_t\\) the AI can take:\n",
        "    - a_t ​ ={Move 1,Move 2,Move 3,Move 4,Switch Pokemon}\n",
        "\n",
        "- **MCTS Process:**\n",
        "  - **Selection:** Use UCT formula to select actions:\n",
        "    - ![image.png](data:image/png;base64,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)\n",
        "    - Q(st ​,a) is the average reward for taking action a in state st​, N(st) is the visit count for state  st​, and N(st,a) is the visit count for action a in state  st.\n",
        "    - (N(s_t)): visit count for state (s_t)\n",
        "    - (N(s_t, a)): visit count for action (a) in state (s_t)\n",
        "  - **Expansion:** Add new nodes for possible actions.\n",
        "  - **Simulation:** Simulate game to terminal state.\n",
        "  - **Evaluation:** Evaluation: Calculate the reward for the terminal state using the evaluation function: Utility(s) = ∑Agent’s Health - ∑ Opponent’s Health\n",
        "  - **Backpropagation:** Update values of visited nodes.\n",
        "\n",
        "### Implementation in Training and Testing\n",
        "- **Training:**\n",
        "  - Use MCTS to explore potential future states and inform decision-making.\n",
        "  - Update search tree with data from each battle (states, actions, rewards).\n",
        "\n",
        "- **Testing:**\n",
        "  - Evaluate AI using proposed metrics.\n",
        "  - Compare against benchmark model to assess AI’s performance.\n",
        "\n",
        "### Benchmark Model\n",
        "- **Definition:**\n",
        "  - Rule-based opponent following predefined strategy (e.g., choosing highest damage move, switching to type-advantaged Pokémon).\n",
        "- **Comparison:**\n",
        "  - AI performance compared to benchmark model using evaluation metrics.\n",
        "  - Improvements in win rate, move effectiveness, and adaptability indicate success.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOs5e5FBxnk"
      },
      "source": [
        "# Ethics & Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB_KCimlBxnk"
      },
      "source": [
        "The main goal of our project is to develop an AI agent using MCTS and RL techniques to make strategic decisions to maximize winning expectations in Pokémon battles. We also seriously consider ethical and privacy aspects in our project.\n",
        "\n",
        "### Data Privacy & Consent\n",
        "- Our project utilizes battle data from various sources, which may include sensitive information regarding the game and its users. To ensure compliance with data privacy regulations:\n",
        "  - All data will be anonymized.\n",
        "  - We will strictly adhere to data protection laws, ensuring the privacy and consent of all individuals involved in the data collection process.\n",
        "\n",
        "### Bias and Representation\n",
        "- The dataset used in our project might contain inherent biases due to factors such as cultural preferences, language, and geographical distribution. We acknowledge that the initial dataset may not equally represent all types of Pokémon battles or strategies.\n",
        "  - We will actively work to minimize and mitigate such biases.\n",
        "  - Our aim is to create a balanced and inclusive AI model that can cater to diverse battling styles and preferences.\n",
        "\n",
        "### Generalization and Impact\n",
        "- Our project dataset is limited, but we aim to develop methods to generalize the AI's performance across various battle scenarios and Pokémon types.\n",
        "  - We will take care to avoid overgeneralization, which could misrepresent certain battle strategies or Pokémon characteristics.\n",
        "  - Our goal is to ensure that the AI provides recommendations and strategies that benefit a broad spectrum of players and battle conditions.\n",
        "\n",
        "### Transparency and Accountability\n",
        "- In line with ethical research practices, we commit to full transparency regarding our methodologies, data sources, and findings.\n",
        "  - We will document and share our research processes.\n",
        "  - This will ensure that our work can be reviewed, reproduced, and validated by others in the community.\n",
        "  - This transparency will help us maintain accountability and foster trust in our project's outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qChrn-t0Bxnk"
      },
      "source": [
        "# Team Expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y37uUaDgBxnl"
      },
      "source": [
        "- **Communication:**\n",
        "  - Each member is expected to keep the team updated on their progress.\n",
        "  - Inform the team in advance if unable to complete assigned work.\n",
        "  - Regularly attend planned meetings and notify the team if unable to attend.\n",
        "\n",
        "- **Collaboration:**\n",
        "  - Respect and listen to each member regardless of differences.\n",
        "  - Work together to achieve project goals and support each other.\n",
        "\n",
        "- **Responsibilities:**\n",
        "  - Complete assigned work on time.\n",
        "  - Notify the team if the workload is too heavy.\n",
        "  - Share progress and challenges openly.\n",
        "\n",
        "- **Meetings:**\n",
        "  - Attend meetings at the agreed times.\n",
        "  - Actively participate in discussions and decision-making.\n",
        "  - Contribute to the development and refinement of project ideas and tasks.\n",
        "\n",
        "- **Accountability:**\n",
        "  - Take responsibility for individual tasks and deliverables.\n",
        "  - Ensure high-quality work and timely completion of assignments.\n",
        "  - Support teammates in their roles and responsibilities.\n",
        "\n",
        "- **Respect and Inclusivity:**\n",
        "  - Create a positive and inclusive team environment.\n",
        "  - Value diverse perspectives and ideas.\n",
        "  - Encourage open and respectful communication.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMOTsczoBxnl"
      },
      "source": [
        "# Project Timeline Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzEcQ8_DBxnl"
      },
      "source": [
        "| Meet Date | Meet Time | Completed Before Meeting            | Discuss at Meeting                                                                 |\n",
        "|-----------|-----------|-------------------------------------|-----------------------------------------------------------------------------------|\n",
        "| 5/9       | 5 PM      | Brainstorm topics/questions         | Determine best way of communication, finalize project idea, discuss problem/solution, determine best days and time for meetings |\n",
        "| 5/14      | 3 PM      | Do background research on topic     | Finalize the ideal dataset for the project, begin draft of project proposal, split independent work                      |\n",
        "| 5/17      | 5 PM      | Edit proposal                       | Agree as a group on team expectations and team calendar, review and edit proposal together, finalize and submit proposal  |\n",
        "| 5/20      | 5 PM      | Begin cleaning the dataset          | Include only battle-related data, assign group members to lead specific parts of the project, discuss analysis plan       |\n",
        "| 6/1       | 5 PM      | Begin programming for project       | Discuss and edit code, plan final steps for project code                                                                |\n",
        "| 6/7       | 5 PM      | Finalize results                    | Draft results/conclusion/discussion, split remaining parts for individual work                                          |\n",
        "| 6/11      | 5 PM      | Review and finalize project         | Turn in final project                                                                                                   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1nHwK-mBxnl"
      },
      "source": [
        "# Footnotes：\n",
        "\n",
        "1. Barradas, A. \"Pokemon with stats.\" Retrieved May 17, 2024, from [Kaggle](https://www.kaggle.com/datasets/abcsds/pokemon/data).\n",
        "2. Nguyen Van Anh, T. \"Pokemon Dataset with Team Combat.\" Retrieved May 17, 2024, from [Kaggle](https://www.kaggle.com/datasets/tuannguyenvananh/pokemon-dataset-with-team-combat).\n",
        "3. Silver, D. et al. \"Mastering the game of Go with deep neural networks and tree search.\" Nature, 529.7587 (2016): 484-489.\n",
        "4. OpenAI. \"OpenAI Five: The world’s first AI to defeat a team of professionals at Dota 2.\" OpenAI, 2018.\n",
        "5. Kaggle dataset on Generation 1 Pokémon: Retrieved May 17, 2024, from [Kaggle](https://www.kaggle.com/abcsds/pokemon).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d0oEf3bBxnl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}